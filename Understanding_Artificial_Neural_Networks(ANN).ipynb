{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extra-bunny",
   "metadata": {},
   "source": [
    "# Neural Networks (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-vancouver",
   "metadata": {},
   "source": [
    "Neural networks is one of the fascinating technology solution to implement AI. We can also say neural networks fastend AI implementation in real life along with Big Data and compute. In this post we'll be learning about all the terminologies in Neural Networks.\n",
    "  - `Perceptron Model to Neural Networks`\n",
    "  - `Activation Functions`\n",
    "  - `Cost Functions`\n",
    "  - `Feed Forward Networks`\n",
    "  - `BackPropagation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-hostel",
   "metadata": {},
   "source": [
    "### Perceptron Model to Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-costa",
   "metadata": {},
   "source": [
    "To being understanding of deep learning, we will build up more model abstractions:\n",
    "   - 1. Single Biological Neuron\n",
    "   - 2. Perceptron\n",
    "   - 3. Multi-layer Perceptron model\n",
    "   - 4. Deep Learning Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-lodging",
   "metadata": {},
   "source": [
    "##### 1. Single Biological Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-leone",
   "metadata": {},
   "source": [
    "If the whole idea of deep learning is to have computers to artificially mimic biological natural intelligence then we should probably build a general understanindg of how biological neurons work. So lets first look a how neurons in our brain is represented,\n",
    "\n",
    "![Biological Neuron](images/NN/bilogical_neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-insider",
   "metadata": {},
   "source": [
    "The main parts of biological neuron are,\n",
    "- Dendrites (input)\n",
    "- Nucleus (neuron)\n",
    "- Axon (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-criterion",
   "metadata": {},
   "source": [
    "#### 2. Perceptron\n",
    "\n",
    "\".. Perceptron may eventually be able to learn, make decisions, and translate languages\"\n",
    "![Perceptron Model](images/NN/perceptron_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-construction",
   "metadata": {},
   "source": [
    "So we want our perceptron model to imitate the real human biological neuron behaviour. Which it does in using the above diagram. To generalize the it more, we will create a mathematical function which is more or less similar to the above one. \n",
    "$$ \\hat{y} = \\sum_{i=1}^{n} x_iw_i + b_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-prerequisite",
   "metadata": {},
   "source": [
    "#### 3. Multi-layer Perceptron model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-forestry",
   "metadata": {},
   "source": [
    "A single layer perceptron is not enough to learn the complicated system/data like today. To solve this \"Multi-Layer Perceptron\" is introduced.\n",
    "![NN](images/NN/NN_Multi_Layer.jpg)\n",
    "\n",
    "Fig :-  A fully connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-metadata",
   "metadata": {},
   "source": [
    "- The first layer is \"input layer\"\n",
    "- the last layer is \"output layer\" (can be one or more than one)\n",
    "- anything between input and output is called \"hidden layer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-surrey",
   "metadata": {},
   "source": [
    "#### 4. Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-fiction",
   "metadata": {},
   "source": [
    "A Neural Network which has 2 or more than 2 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-reynolds",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-defendant",
   "metadata": {},
   "source": [
    "We want to set boudaries for the overall output for $ x*w + b $ or  $z = x*w+b $ and pass this z value to activation function to limit its value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-chassis",
   "metadata": {},
   "source": [
    " - Sigmoid\n",
    " - Tanh\n",
    " - Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-tomato",
   "metadata": {},
   "source": [
    "##### 1. Sigmoid (logistic, soft step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-authorization",
   "metadata": {},
   "source": [
    "![sigmoid](images/Activation_Functions/sigmoid.png)\n",
    " - Sigmoid function outputs values in between 0 and 1. \n",
    " - Function f(x) :-  $ \\sigma(x) = \\frac{1}{1+e^{-x}} $\n",
    " - Derivative   :- $ f(x)(1-f(x)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-bolivia",
   "metadata": {},
   "source": [
    "#### 2. Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-prescription",
   "metadata": {},
   "source": [
    "![tanh](images/Activation_Functions/tanh.png)\n",
    "\n",
    " - Tanh function outputs values in between -1 and 1. \n",
    " - Function f(x) :-  $ tanh(x) = \\frac{sinhx}{coshx} = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$\n",
    " - Derivative   :- $ 1-f(x)^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-chart",
   "metadata": {},
   "source": [
    "#### 3. Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-vampire",
   "metadata": {},
   "source": [
    "![tanh](images/Activation_Functions/relu.png)\n",
    "\n",
    " - Tanh function outputs values in between 0 and max(x). \n",
    " - Function f(x) :-  $ max(0, x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-uzbekistan",
   "metadata": {},
   "source": [
    "### Cost Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-screen",
   "metadata": {},
   "source": [
    "cost function also called as loss function. After network output the predictions, how do we evaluate it? and after the evaluation how can we update the network's weights and biases? . After the predictions, we'll compare the output predicted with output true and estimate the loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-material",
   "metadata": {},
   "source": [
    "The cost function must be an average so it can output a single value. We can keep track of our loss/cost during training to monitor network performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-south",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-ireland",
   "metadata": {},
   "source": [
    "###### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-harassment",
   "metadata": {},
   "source": [
    "We simply calculate the diff between actual values and predicted values\n",
    "$$ \\frac{1}{2n} \\sum_{x} {||y(x) - a^L(x)||}^2 $$\n",
    "- $ a^L $ -  activation for Last layer\n",
    "- squaring does 2 helps for us ,one is eberything postitve and punishes large errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-moment",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-karen",
   "metadata": {},
   "source": [
    "If we want to minimize our loss value, we need to figure out what value of \"w\" will result in very low cost. We could start with larger steps (learning rate), then go smaller as we realize the slope gets closer to zero. This is known as adaptive gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-victory",
   "metadata": {},
   "source": [
    "### Feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-initial",
   "metadata": {},
   "source": [
    "more on this [FeedForward Pass](https://github.com/smsrikanthreddy/deep_learning/blob/main/NN_Feedforward.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-juice",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-nature",
   "metadata": {},
   "source": [
    "Fundamentally, we want to know, how the cost function change with update to its weights (w) in the network. So we can update the weights to minimize the cost function. The goal of backpropagation is to optimize the weights so that the neural network can learn how to correctly map arbitrary inputs to outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-listing",
   "metadata": {},
   "source": [
    "more on this [Backpropagation](https://github.com/smsrikanthreddy/deep_learning/blob/main/NN_backpropagation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-amber",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-fighter",
   "metadata": {},
   "source": [
    "1. https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-substance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
